# Active LLM Provider (options: 'gemini', 'local', 'none')
ACTIVE_LLM=local

# Gemini API Key (if using Gemini)
GEMINI_API_KEY=your_gemini_api_key_here

# Ollama Configuration
OLLAMA_MODEL=llama3.2  # or your preferred model
OLLAMA_HOST=http://localhost:11434  # default Ollama server address
